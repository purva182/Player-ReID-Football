
# âš½ Player Re-Identification Across Cameras using DeepSORT + OSNet

This project aims to identify and track football players across two different video perspectives: a **broadcast view** and a **tacticam view**. It combines **multi-object tracking (MOT)** with **Re-Identification (Re-ID)** using visual, spatial, and temporal cues.

## ğŸš€ Overview

- **Task**: Match players across two unsynchronized camera feeds.
- **Approach**:
  - Detect players in both videos using a pre-trained object detector (`best.pt` from LIAT.ai).
  - Track players over time using **DeepSORT**.
  - Extract deep appearance features using **OSNet**.
  - Match players between cameras using **cosine similarity** on averaged embeddings.
  - Visualize matches in a side-by-side video.

## ğŸ§  Features Used

| Feature Type | Description                          | Usage                          |
|--------------|--------------------------------------|--------------------------------|
| ğŸ¨ Visual    | Player appearance (jersey, color)    | Extracted via OSNet embeddings |
| ğŸ“ Spatial   | Bounding box positions               | Used by DeepSORT for tracking  |
| ğŸ•’ Temporal  | Track consistency over time          | Maintained by DeepSORT         |

## ğŸ› ï¸ Dependencies

- Python 3.8+
- OpenCV
- PyTorch
- torchvision
- numpy
- PIL
- [torchreid](https://github.com/KaiyangZhou/deep-person-reid)
- gdown

Install dependencies:

```bash
pip install opencv-python torch torchvision numpy pillow gdown
pip install git+https://github.com/KaiyangZhou/deep-person-reid.git
 [nwojke/deep_sort](https://github.com/nwojke/deep_sort) (original DeepSORT algorithm)
```

## ğŸ“‚ Folder Structure

```
â”œâ”€â”€ broadcast.mp4
â”œâ”€â”€ tacticam.mp4
â”œâ”€â”€ broadcast_tracked_with_ids.json
â”œâ”€â”€ tacticam_tracked_with_ids.json
â”œâ”€â”€ broadcast_embeddings1.json
â”œâ”€â”€ tacticam_embeddings1.json
â”œâ”€â”€ player_matches.json
â”œâ”€â”€ matched_side_by_side1.mp4
â”œâ”€â”€ run_deepsort.py
â”œâ”€â”€ osnet_embeddings.py
â”œâ”€â”€ match_players.py
â”œâ”€â”€ visualize_matches.py
â””â”€â”€ README.md
```

## ğŸ§ª How to Run

### 1. Run DeepSORT Tracking on Both Videos

```bash
python run_deepsort.py
```

### 2. Extract OSNet Embeddings

```bash
python osnet_embeddings.py
```

### 3. Match Players Using Cosine Similarity

```bash
python match_players.py
```

### 4. Visualize Matches

```bash
python visualize_matches.py
```

## ğŸ“ˆ Results

- âœ… Tracked players across both camera views
- âœ… Generated ID-based mapping file: `player_matches.json`
- âœ… Created side-by-side visualization video: `matched_side_by_side1.mp4`
- âœ… Used DeepSORT + OSNet pipeline effectively

## âš ï¸ Limitations

- âŒ No ground truth available to compute numeric accuracy.
- ğŸš« Embeddings are not fine-tuned â€” pre-trained OSNet used as-is.
- ğŸ¥ Videos are not perfectly synchronized; minor mismatches may occur.
- ğŸ§ª Visual similarity does not always guarantee true identity match.

## âœ… Evaluation Strategy (Without Ground Truth)

- **Cosine similarity** between player embeddings used as matching score.
- **Visual validation** via annotated side-by-side video.
- **Manual spot-checking** for consistency of IDs over time.

## ğŸ“Œ Future Work

- Fine-tune OSNet on domain-specific football data.
- Incorporate pose/keypoint-based features for better disambiguation.
- Use a frame-synchronization module to improve match alignment.
- Add mAP/CMC-style evaluation if annotations become available.

## ğŸ§‘â€ğŸ’» Author

This project was completed as part of an internship assignment.  
If shortlisted, the system can be extended further into a real-time, multi-camera tracking system.
